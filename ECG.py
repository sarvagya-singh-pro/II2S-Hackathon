# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11GvauBDLfV9mzpz1Ntcx-6_jqGBOcD8f
"""

from google.colab import files
files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d danialsharifrazi/hypertrophic-cardiomyopathy-dataset

!unzip hypertrophic-cardiomyopathy-dataset.zip

# Import necessary libraries
from tensorflow.keras.models import Sequential, save_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
import os
import shutil
from sklearn.model_selection import train_test_split
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Define paths for saving model checkpoints
checkpoint_path = "/content/drive/My Drive/checkpoints/cp-{epoch:04d}.h5"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Directory where the dataset is stored in the Colab VM
data_dir = '/content/HCM'  # Replace with your dataset path
print(data_dir)

# List of classes (subdirectories)
classes = os.listdir(data_dir)
print(classes)

# Dictionary to store image paths by class
data = {cls: [] for cls in classes}

# Iterate over each class
for cls in classes:
    cls_path = os.path.join(data_dir, cls)
    # Skip non-directory files
    if os.path.isdir(cls_path):
        # Recursively iterate through all subdirectories
        for root, dirs, files in os.walk(cls_path):
            # Add full image paths to the dictionary
            data[cls].extend([os.path.join(root, file) for file in files])

# Split the data into training, validation, and test sets for each class
train_data, validation_data, test_data = {}, {}, {}
for cls, images in data.items():
    # Split data into training (70%) and test (30%) sets
    train_images, test_images = train_test_split(images, test_size=0.3, random_state=42)

    # Split test data into test (10%) and validation (20%) sets
    validation_images, test_images = train_test_split(test_images, test_size=0.33, random_state=42)

    # Store image paths in the appropriate dictionaries
    train_data[cls] = train_images
    validation_data[cls] = validation_images
    test_data[cls] = test_images

# Verify data distribution
for cls in classes:
    print(f"Class: {cls}")
    print(f"Training data size: {len(train_data[cls])}")
    print(f"Test data size: {len(test_data[cls])}")
    print(f"Validation data size: {len(validation_data[cls])}")
    print("---------------------------")

# Complete paths for training, validation, and test directories
train_data_dir = '/content/train_data'
test_data_dir = '/content/test_data'
validation_data_dir = '/content/validation_data'
print(train_data_dir)
print(test_data_dir)
print(validation_data_dir)

# Create training and test directories
os.makedirs(train_data_dir, exist_ok=True)
os.makedirs(test_data_dir, exist_ok=True)
os.makedirs(validation_data_dir, exist_ok=True)

# Copy images to the appropriate directories
for cls, paths in train_data.items():
    cls_dir = os.path.join(train_data_dir, cls)
    os.makedirs(cls_dir, exist_ok=True)
    for path in paths:
        shutil.copy(path, cls_dir)

for cls, paths in test_data.items():
    cls_dir = os.path.join(test_data_dir, cls)
    os.makedirs(cls_dir, exist_ok=True)
    for path in paths:
        shutil.copy(path, cls_dir)

for cls, paths in validation_data.items():
    cls_dir = os.path.join(validation_data_dir, cls)
    os.makedirs(cls_dir, exist_ok=True)
    for path in paths:
        shutil.copy(path, cls_dir)

# Model parameters
input_shape = (150, 150, 1)  # Updated for grayscale images
batch_size = 64
epochs = 20
learning_rate = 0.001
dropout_rate = 0.5

# Data augmentation for enriching the training set
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='binary',
    color_mode='grayscale'  # Handle grayscale images
)

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='binary',
    color_mode='grayscale'  # Handle grayscale images
)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='binary',
    color_mode='grayscale'  # Handle grayscale images
)

# Create the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(dropout_rate))
model.add(Dense(1, activation='sigmoid'))

# Compile the model with an Adam optimizer and specified learning rate
optimizer = Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Callback for saving the entire model after each epoch
checkpoint_callback = ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=False,  # Save entire model including architecture
    verbose=1,
    save_freq='epoch'  # Save model after every epoch
)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size,
    callbacks=[checkpoint_callback]
)

# Import libraries
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# Assuming you have saved the best model checkpoint
model_path = "/content/drive/My Drive/checkpoints/cp-0020.h5"  # Replace with your checkpoint path
model = load_model(model_path)  # Load the best model

input_shape = (150, 150, 1)  # Adjust based on your image dimensions
batch_size = 64

# Prepare data generators for test set (modify if needed)
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    train_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='binary',
    color_mode='grayscale',  # Handle grayscale images
    shuffle=False
)

# Get predictions on the test set
predictions = model.predict_generator(test_generator)

# Convert predictions to class labels (round for binary classification)
predicted_classes = np.round(predictions).astype(int)

# Get true labels from the test generator (modify if labels are stored differently)
true_labels = test_generator.classes

# Calculate confusion matrix
cm = confusion_matrix(true_labels, predicted_classes)

# Plot the confusion matrix
plt.figure(figsize=(8, 8))
plt.imshow(cm, cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.xticks(range(len(classes)), classes, rotation=45)
plt.yticks(range(len(classes)), classes)
plt.colorbar()
plt.ylabel('True Label')
plt.xlabel('Predicted Label')

# Add text labels to each cell
for i in range(len(classes)):
  for j in range(len(classes)):
    plt.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.mean() else 'black')

plt.tight_layout()
plt.show()

TP = 779
TN = 2118
FP = 1261
FN = 1273

accuracy = (TP + TN) / (TP + TN + FP + FN)
precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1_score = 2 * (precision * recall) / (precision + recall)
specificity = TN / (TN + FP)
npv = TN / (TN + FN)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1_score)
print("Specificity:", specificity)
print("Negative Predictive Value:", npv)

from google.colab import drive
# Mount Google Drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
from lime import lime_image
from skimage.segmentation import mark_boundaries

# Load your trained model
model = tf.keras.models.load_model('/content/drive/My Drive/checkpoints/cp-0014.h5')  # Replace with your model path

# Function to load and preprocess a grayscale image
def load_and_preprocess_image(img_path, target_size=(150, 150)):
    img = load_img(img_path, color_mode='grayscale', target_size=target_size)
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale to [0, 1]
    return img_array

# Path to your grayscale test image
test_img_path = "/content/HCM/Sick/Directory_22/series0001-Body/img0001--9.jpg"  # Replace with your image path

# Load and preprocess the image
img_array = load_and_preprocess_image(test_img_path)
img = img_array[0]  # Remove batch dimension for LIME

# Convert grayscale image to 3-channel image
img_rgb = np.repeat(img, 3, axis=-1)

# Define prediction function for LIME
def predict_fn(images):
    # Convert 3-channel images back to grayscale for the model
    images_gray = np.mean(images, axis=-1, keepdims=True)
    preds = model.predict(images_gray)
    return preds

# Initialize LIME explainer
explainer = lime_image.LimeImageExplainer()

# Explain the prediction
explanation = explainer.explain_instance(img_rgb.astype('double'), predict_fn, top_labels=2, hide_color=0, num_samples=1000)

# Get the explanation for the top class
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=False)

# Display the original image and LIME explanation
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title('Original Grayscale Image')
plt.imshow(np.squeeze(img_array[0]), cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('LIME Explanation')
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))
plt.axis('off')

plt.tight_layout()
plt.show()

!pip install lime

import tensorflow as tf
# Assuming your model is already loaded
model = tf.keras.models.load_model('/content/drive/My Drive/checkpoints/cp-0014.h5')  # Replace with your model path

# Print the model summary to see the layers
print(model.summary())

# Example to find the last convolutional layer
last_conv_layer_name = None
for layer in model.layers[::-1]:
    if isinstance(layer, tf.keras.layers.Conv2D):
        last_conv_layer_name = layer.name
        break

print(f"Last Convolutional Layer Name: {last_conv_layer_name}")